{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "NOTION_SECRET = os.getenv(\"NOTION_SECRET\")\n",
    "DATABASE_ID = os.getenv(\"DATABASE_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_book_search(title, author, publisher):\n",
    "    search_terms = \" \".join(filter(None, [title, author, publisher]))\n",
    "    url = 'https://www.googleapis.com/books/v1/volumes?q='\n",
    "    response = requests.get(url+search_terms)\n",
    "    data = response.json()\n",
    "    # Normalizing data\n",
    "    df = pd.json_normalize(data, record_path=['items'])\n",
    "    return df\n",
    "\n",
    "\n",
    "search_terms = \"maniac labatut\"\n",
    "url = 'https://www.googleapis.com/books/v1/volumes?q='\n",
    "response = requests.get(url+search_terms)\n",
    "data = response.json()\n",
    "# # Normalizing data\n",
    "df = pd.json_normalize(data, record_path=['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_databases(secret_key, database_id):\n",
    "    url = \"https://api.notion.com/v1/databases/\"+database_id+'/query'\n",
    "\n",
    "    payload = {'id': database_id}\n",
    "    headers = {\n",
    "        'Notion-Version': '2021-05-13',\n",
    "        'Authorization': 'Bearer '+secret_key\n",
    "    }\n",
    "\n",
    "    response = requests.request(\n",
    "        \"POST\", url, headers=headers, data=payload)\n",
    "    print(f\"The response code is {response.status_code}\")\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    else:\n",
    "        return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = query_databases(NOTION_SECRET, DATABASE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.get('results')[0].get('properties')[\n",
    "    'Summary']['rich_text'][0].get('plain_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notion_columns = ['Category', 'Publisher', 'Summary', 'Current page', 'Link',\n",
    "                  'Total pages', 'Date started', 'Author', 'Title', 'url', 'page_id']\n",
    "notion = pd.DataFrame(columns=notion_columns)\n",
    "print(notion.columns)\n",
    "print(notion.head())\n",
    "for page in res.get('results'):\n",
    "    properties = page.get('properties')\n",
    "    try:\n",
    "        author = properties.get('Author').get('rich_text')[0].get('plain_text')\n",
    "    except IndexError:\n",
    "        author = None\n",
    "    try:\n",
    "        title = properties.get('Title').get('title')[0].get('plain_text')\n",
    "    except IndexError:\n",
    "        title = None\n",
    "    try:\n",
    "        publisher = properties['Publisher']['select']['name']\n",
    "    except KeyError:\n",
    "        publisher = None\n",
    "    try:\n",
    "        category = properties['Category']['select']['name']\n",
    "    except KeyError:\n",
    "        category = None\n",
    "    try:\n",
    "        summary = properties['Summary']['rich_text'][0]['plain_text']\n",
    "    except IndexError:\n",
    "        summary = None\n",
    "    try:\n",
    "        current_page = properties['Current page']['number']\n",
    "    except KeyError:\n",
    "        current_page = None\n",
    "    try:\n",
    "        link = properties['Link']['url']\n",
    "    except KeyError:\n",
    "        link = None\n",
    "    total_pages = properties['Total pages']['number']\n",
    "    try:\n",
    "        date_started = properties['Date started']['date']['start']\n",
    "    except KeyError:\n",
    "        date_started = None\n",
    "\n",
    "    url = page.get('url')\n",
    "    page_id = url[-32:]\n",
    "    # concat the data\n",
    "    notion = pd.concat([notion, pd.DataFrame([[category, publisher, summary, current_page, link, total_pages,\n",
    "                       date_started, author, title, url, page_id]], columns=notion_columns)], ignore_index=True)\n",
    "# drop rows without title\n",
    "notion = notion.dropna(subset=['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_results = pd.DataFrame()\n",
    "\n",
    "for book in notion.itertuples():\n",
    "\n",
    "    google_results = pd.concat([google_results, google_book_search(\n",
    "        book.Title, book.Author, book.Publisher)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "google_data = google_results[['selfLink', 'volumeInfo.title',\n",
    "                              'volumeInfo.subtitle', 'volumeInfo.authors', 'volumeInfo.publisher',\n",
    "                              'volumeInfo.publishedDate', 'volumeInfo.description', 'volumeInfo.pageCount', 'volumeInfo.categories',\n",
    "                              'volumeInfo.imageLinks.smallThumbnail', 'volumeInfo.imageLinks.thumbnail', 'saleInfo.country', 'saleInfo.retailPrice.amount',\n",
    "                              'saleInfo.retailPrice.currencyCode'\n",
    "                              ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def clean_google_data(google_df, notion_df):\n",
    "    filtered_results = []\n",
    "\n",
    "    for _, notion_row in notion_df.iterrows():\n",
    "        try:\n",
    "            # Convert Notion title to lowercase and split into words\n",
    "            notion_title_words = notion_row['Title'].lower().split()\n",
    "            # Create a regex pattern to match all words\n",
    "            pattern = '.*'.join(notion_title_words)\n",
    "            # Filter google_df by title using regex\n",
    "            matches = google_df[google_df['volumeInfo.title'].str.lower(\n",
    "            ).str.contains(pattern, regex=True, na=False)]\n",
    "            # add page_id to matches as column\n",
    "            matches['page_id'] = notion_row['page_id']\n",
    "\n",
    "        except TypeError as e:\n",
    "            print(f\"TypeError encountered while filtering by title: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Further filter by author if available\n",
    "            if pd.notna(notion_row.get('Author')):\n",
    "                tmp_df = matches[matches['volumeInfo.authors'].apply(\n",
    "                    lambda authors: notion_row['Author'] in authors if isinstance(authors, list) else False)]\n",
    "                if not tmp_df.empty:  # If there are matches, keep them\n",
    "                    matches = tmp_df\n",
    "        except TypeError as e:\n",
    "            print(f\"TypeError encountered while filtering by author: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Further filter by publisher if available\n",
    "            if pd.notna(notion_row.get('Publisher')):\n",
    "                tmp_df = matches[matches['volumeInfo.publisher'].apply(\n",
    "                    lambda publisher: notion_row['Publisher'] == publisher if isinstance(publisher, str) else False)]\n",
    "                if not tmp_df.empty:  # If there are matches, keep them\n",
    "                    matches = tmp_df\n",
    "\n",
    "        except TypeError as e:\n",
    "            print(f\"TypeError encountered while filtering by publisher: {e}\")\n",
    "            continue\n",
    "        try:\n",
    "            # If there are matches, keep the latest by published_date\n",
    "            latest_match = matches.sort_values(\n",
    "                by='volumeInfo.publishedDate', ascending=False).iloc[0]\n",
    "            filtered_results.append(latest_match)\n",
    "        except IndexError as e:\n",
    "            # only single match, append\n",
    "            if not matches.empty:\n",
    "                filtered_results.append(matches)\n",
    "            else:\n",
    "                print(f\"No match found for {notion_row['Title']}\")\n",
    "            continue\n",
    "        except KeyError:\n",
    "            if not matches.empty:\n",
    "                filtered_results.append(matches)\n",
    "            else:\n",
    "                print(f\"No match found for {notion_row['Title']}\")\n",
    "            continue\n",
    "\n",
    "    # Convert the list of filtered results to a DataFrame\n",
    "    filtered_df = pd.DataFrame(filtered_results)\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_google_data = clean_google_data(google_data, notion)\n",
    "clean_google_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_google_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge clean google and notion data on page_id\n",
    "complete = pd.merge(notion, clean_google_data, on='page_id', how='left')\n",
    "complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Notion with Google Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update a property on a page based on property type\n",
    "def update_page(row, property_name, property_type, data_column, verbose=False):\n",
    "    url = f\"https://api.notion.com/v1/pages/{row.page_id}\"\n",
    "\n",
    "    # erxtract the property value\n",
    "    property_value = row[data_column]\n",
    "\n",
    "    # Check the property type and create the payload\n",
    "    if property_type == 'date':\n",
    "        property_payload = {\n",
    "            \"start\": property_value\n",
    "        }\n",
    "    elif property_type == 'url':\n",
    "        property_payload = property_value\n",
    "    elif property_type == 'number':\n",
    "        property_payload = property_value\n",
    "    elif property_type == 'rich_text':\n",
    "        property_payload = [{\n",
    "            \"type\": \"text\",\n",
    "            \"text\": {\n",
    "                \"content\": property_value\n",
    "            }\n",
    "        }]\n",
    "    elif property_type == 'select':\n",
    "        property_payload = {\n",
    "            \"name\": property_value\n",
    "        }\n",
    "\n",
    "    payload = json.dumps({\n",
    "        \"properties\": {\n",
    "            property_name: {\n",
    "                property_type: property_payload\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Notion-Version': '2021-05-13',\n",
    "        'Authorization': f'Bearer {NOTION_SECRET}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\n",
    "        \"PATCH\", url, headers=headers, data=payload)\n",
    "    if verbose:\n",
    "        print(response.status_code)\n",
    "    errors = []\n",
    "    if response.status_code != 200:\n",
    "        errors.append(response.text)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update publishing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_google_data.apply(lambda row: update_page(\n",
    "    row, \"Published\", \"date\", \"volumeInfo.publishedDate\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_google_data.apply(lambda row: update_page(\n",
    "    row, \"Link\", \"url\", \"selfLink\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_google_data.apply(lambda row: update_page(\n",
    "    row, \"Publisher\", \"select\", \"volumeInfo.publisher\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_google_data.apply(lambda row: update_page(\n",
    "    row, \"Total pages\", \"number\", \"volumeInfo.pageCount\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_errors = clean_google_data.apply(lambda row: update_page(\n",
    "    row, \"Summary\", \"rich_text\", \"volumeInfo.description\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_page_icon(row, data_column, icon_or_cover):\n",
    "\n",
    "    page_id = row['page_id']\n",
    "    property_value = row[data_column]\n",
    "\n",
    "    url = f\"https://api.notion.com/v1/pages/{page_id}\"\n",
    "\n",
    "    payload = json.dumps({icon_or_cover: {\n",
    "        \"type\": \"external\",\n",
    "        \"external\": {\n",
    "                \"url\": property_value\n",
    "        }}})\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Notion-Version': '2021-05-13',\n",
    "        'Authorization': f'Bearer {NOTION_SECRET}'\n",
    "    }\n",
    "\n",
    "    response = requests.request(\n",
    "        \"PATCH\", url, headers=headers, data=payload)\n",
    "    errors = []\n",
    "    if response.status_code != 200:\n",
    "        print(payload)\n",
    "        errors.append(response.text)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon_errors = clean_google_data.apply(lambda row: update_page_icon(\n",
    "    row, 'volumeInfo.imageLinks.smallThumbnail', 'icon'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_errors = clean_google_data.apply(lambda row: update_page_icon(\n",
    "    row, 'volumeInfo.imageLinks.smallThumbnail', 'cover'), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
